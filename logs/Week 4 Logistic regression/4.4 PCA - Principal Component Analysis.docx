PCA (Principal Component Analysis) is a technique in ML and AI to
    reduce dimensionality of data wile preserving as much variance (information) as possible

    It transforms original features to a new set of features called Prinicpal Components
    These Principal Components are uncorrelated and ordered by the amount of variance they capture

Why use PCA?
    1. To simplify complex datasets
    2. To visualize high-dimensional data
    3. To speed up learning algorithms
    4. To remove noise and redundancy

PCA is basically a preprosessing step in ML

How to decide number of components to consider
    Each principal component has an eigenvalue (variance it explains)
    Explained variance ratio tells us the fraction of total variance captured by each component
    Decision rule: Keep enough components so that the cumulative explained variance exceeds threshold (90 - 95%)

    Cross validaton (Practical ML Approach)
        Train your model with different numbers of components
        Compare performance (accuracy, error, etc)
        Choose the smallest number of compoenents that gives good performance